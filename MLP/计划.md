# 📅 分阶段学习与实现计划（详细版）

## **阶段 1：理解 MLP 前向推理的基本原理**

🔹 **目标**：理解 MLP 是什么，前向推理是如何计算的。

### 学习任务

1. 学习神经网络最基础的公式：
   * 单个神经元计算：`y = W·x + b`
   * 激活函数作用：非线性（ReLU / Sigmoid / Softmax）
2. 理解 MLP 的结构：
   * 输入层 → 隐藏层（全连接 + ReLU） → 输出层（全连接 + Softmax）。
3. 学会 Softmax 的意义：把输出转化为概率分布。

### 实践任务

* 用纸笔画一个小型 MLP（比如输入维度 4 → 隐藏层 5 → 输出层 3）。
* 手算一次推理：
  * 给定一个输入向量和小的权重矩阵（整数），计算全连接层、ReLU、Softmax 的结果。
* 在 C++ 中写伪代码（不用写真正的代码），模拟这个过程。

---

## **阶段 2：输入数据与矩阵表示**

🔹 **目标**：把输入数据（图像或向量）转换为 Eigen 矩阵，理解矩阵维度。

### 学习任务

1. 复习 Eigen 基础：`MatrixXd`、`VectorXd`、矩阵乘法、逐元素操作。
2. 了解输入数据的表示：
   * 图像作为输入（OpenCV → Mat → Eigen::VectorXd）。
   * 普通向量输入（手动写一个数组）。

### 实践任务

* 使用 OpenCV 读取一张小图片（比如 28×28 MNIST 手写数字）。
* 把像素值转换成 0\~1 的 double 类型，存入 Eigen 向量。
* 打印输入向量维度，确保理解输入形状。

---

## **阶段 3：全连接层（Dense Layer）的实现**

🔹 **目标**：实现 MLP 的核心算子：全连接层。

### 学习任务

1. 全连接层的公式：
   * `output = W * input + b`
   * `W` 是 [输出维度 × 输入维度] 矩阵
   * `b` 是 [输出维度] 向量
2. 理解矩阵乘法的意义：多个神经元同时计算。

### 实践任务

* 定义一个 DenseLayer 类（包含 W 和 b）。
* 随机初始化 W 和 b（比如正态分布）。
* 输入一个向量，计算输出。
* 验证维度是否正确（比如输入 4 维 → 输出 5 维）。

---

## **阶段 4：激活函数的实现**

🔹 **目标**：实现 ReLU 和 Softmax。

### 学习任务

1. **ReLU**：`f(x) = max(0, x)`，逐元素操作。
2. **Softmax**（数值稳定版）：
   * `shifted = x - max(x)`
   * `exp(shifted)`
   * `softmax = exp(shifted) / sum(exp(shifted))`

### 实践任务

* 定义 Activation 类：
  * `VectorXd relu(VectorXd x)`
  * `VectorXd softmax(VectorXd x)`
* 输入一个向量，检查 ReLU 和 Softmax 输出是否正确：
  * ReLU：所有负数应变成 0。
  * Softmax：所有输出 ≥0 且总和约等于 1。

---

## **阶段 5：搭建前向推理流程**

🔹 **目标**：把全连接层和激活函数组合起来。

### 学习任务

1. 理解 MLP 的计算顺序：
   * 输入 → Dense → ReLU → Dense → Softmax。
2. 输出的含义：每个类别的概率。

### 实践任务

* 写一个简单的 MLP 类：
  * 构造函数：初始化各层（权重、偏置）。
  * `forward()` 方法：依次调用 Dense + 激活。
* 输入一个向量，得到最终概率分布。
* 验证 Softmax 输出是否正确（总和为 1）。

---

## **阶段 6：参数管理与模型加载**

🔹 **目标**：能够加载训练好的模型参数，而不是随机初始化。

### 学习任务

1. 学会存储权重矩阵：
   * Python 训练 → 导出为 `.txt` 或 `.npy`。
   * C++ 读取并加载到 Eigen 矩阵。
2. 确保维度对齐。

### 实践任务

* 在 Python 里用 Numpy 随机生成一组 W 和 b，并保存到文件。
* 在 C++ 中加载这些文件，构建 DenseLayer。
* 验证输入相同，C++ 和 Python 推理结果一致。

---

## **阶段 7：测试与验证**

🔹 **目标**：验证你的框架能在真实数据上运行。

### 学习任务

1. 理解 MNIST 分类任务：输入 28×28 图像，输出 10 个类别概率。
2. 用 Python 训练一个简单的 MLP（输入 784 → 隐藏层 128 → 输出 10）。
3. 保存训练好的权重，导入 C++ 推理框架。

### 实践任务

* 用你的 C++ 框架读取 MNIST 图片。
* 输入模型，得到 10 维概率分布。
* 打印预测的类别。

---

## **阶段 8：优化与扩展**

🔹 **目标**：提升性能和扩展功能。

### 学习任务

* 批量输入（Batch）推理：输入 [N×D] 矩阵，一次算 N 个样本。
* 加入更多层（BatchNorm、Dropout）。
* 用 Eigen 的并行化（SIMD / OpenMP）。
* 尝试支持 ONNX 模型加载（通用化）。

### 实践任务

* 对比单张推理和批量推理的性能。
* 加入 `Layer` 基类，让 MLP 可以自由堆叠层。
* 尝试扩展到 CNN（卷积层）。
